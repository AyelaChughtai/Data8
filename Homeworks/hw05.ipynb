{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Functions and Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading**: \n",
    "* [Cross-Classifying by more than one variable](https://www.inferentialthinking.com/chapters/08/3/cross-classifying-by-more-than-one-variable.html) \n",
    "* [Bike Sharing](https://www.inferentialthinking.com/chapters/08/5/bike-sharing-in-the-bay-area.html) \n",
    "* [Randomness](https://www.inferentialthinking.com/chapters/09/randomness.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests. Each time you start your server, you will need to execute this cell again to load the tests.\n",
    "\n",
    "Homework 5 is due Thursday, 2/28 at 11:59pm. You will receive an early submission bonus point if you turn in your final submission by Wednesday, 2/27 at 11:59pm. Start early so that you can come to office hours if you're stuck. Check the website for the office hours schedule. Late work will not be accepted as per the [policies](http://data8.org/sp19/policies.html) of this course. \n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "For all problems that you must write our explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: Homework 5: Functions and Iteration\n",
      "OK, version v1.12.5\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Don't change this cell; just run it. \n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw05.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing the assignment, select \"Save and Checkpoint\" in the File menu and then execute the submit cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to okpy.org and flag the correct version. There will be another submit cell at the end of the assignment when you finish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving notebook... Saved 'hw05.ipynb'.\n",
      "Submit... 100% complete\n",
      "Submission successful for user: ayelachughtai@berkeley.edu\n",
      "URL: https://okpy.org/cal/data8/sp19/hw05/submissions/wVKZBX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with Text using Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table contains the words from four chapters of Charles Dickens' [*A Tale of Two Cities*](http://www.gutenberg.org/cache/epub/98/pg98.txt).  We're going to compute some simple facts about each chapter.  Since we're performing the same computation on each chapter, it's best to encapsulate each computational procedure in a function, and then call the function several times. Run the cell to get a table with one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Chapter text</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>I. The Period\n",
       "\n",
       "\n",
       "It was the best of times,\n",
       "it was the wor ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>II. The Mail\n",
       "\n",
       "\n",
       "It was the Dover road that lay, on a Frid ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>III. The Night Shadows\n",
       "\n",
       "\n",
       "A wonderful fact to reflect upo ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>IV. The Preparation\n",
       "\n",
       "\n",
       "When the mail got successfully to  ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Chapter text\n",
       "I. The Period\n",
       "\n",
       "\n",
       "It was the best of times,\n",
       "it was the wor ...\n",
       "II. The Mail\n",
       "\n",
       "\n",
       "It was the Dover road that lay, on a Frid ...\n",
       "III. The Night Shadows\n",
       "\n",
       "\n",
       "A wonderful fact to reflect upo ...\n",
       "IV. The Preparation\n",
       "\n",
       "\n",
       "When the mail got successfully to  ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just run this cell to load the data.\n",
    "tale_chapters = Table.read_table(\"tale.csv\")\n",
    "tale_chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Write a function called `word_count` that takes a single argument, the text of a single chapter, and returns the number of words in that chapter.  Assume that words are separated from each other by spaces. \n",
    "\n",
    "*Hint:* Try the string method [`split`](https://docs.python.org/3/library/stdtypes.html#str.split) and the function [`len`](https://docs.python.org/3/library/functions.html#len)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count(x):\n",
    "    y = x.split(' ')\n",
    "    return len(y)\n",
    "word_count(tale_chapters.column(\"Chapter text\").item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q1_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Create an array called `chapter_lengths` which contains the length of each chapter in `tale_chapters`. The length of a chapter is equivalent to the number of words in that chapter.\n",
    "\n",
    "**Hint:** Consider using `apply` along with the function you have defined in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 911, 1827, 1468, 3994])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_lengths = tale_chapters.apply(word_count, 'Chapter text')\n",
    "chapter_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q1_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Write a function called `character_count`.  It should take a string as its argument and return the number of characters in that string that aren't spaces (\" \"), periods (\".\"), exclamation marks (\"!\"), or question marks (\"?\"). Remember that `tale_chapters` is a table, and that the function takes in only the text of one chapter as input.\n",
    "\n",
    "*Hint:* Try using the string method `replace` several times to remove the characters we don't want to count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4860"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def character_count(x):\n",
    "    y = x.replace('.', '').replace('?', '').replace(' ', '').replace('!', '')\n",
    "    return len(y)\n",
    "\n",
    "character_count(tale_chapters.column('Chapter text').item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q1_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Write a function called `chapter_number`.  It should take a single argument, the text of a chapter from our dataset, and return the number of that chapter, as a Roman numeral.  (For example, it should return the string \"I\" for the first chapter and \"II\" for the second.)  If the argument doesn't have a chapter number in the same place as the chapters in our dataset, `chapter_number` can return whatever you like.\n",
    "\n",
    "To help you with this, we've included a function called `text_before`.  Its documentation describes what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'III'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_before(full_text, pattern):\n",
    "    \"\"\"Finds all the text that occurs in full_text before the specified pattern.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    full_text : str (String)\n",
    "        The text we want to search within.\n",
    "    pattern : str (String)\n",
    "        The thing we want to search for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str (String)\n",
    "        All the text that occurs in full_text before pattern.  If pattern\n",
    "        doesn't appear anywhere, all of full_text is returned.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    \n",
    "    >>> text_before(\"The rain in Spain falls mainly on the plain.\", \"Spain\")\n",
    "    'The rain in '\n",
    "    >>> text_before(\"The rain in Spain falls mainly on the plain.\", \"ain\")\n",
    "    'The r'\n",
    "    >>> text_before(\"The rain in Spain falls mainly on the plain.\", \"Portugal\")\n",
    "    'The rain in Spain falls mainly on the plain.'\n",
    "    \"\"\"\n",
    "    return np.array(full_text.split(pattern)).item(0)\n",
    "\n",
    "def chapter_number(chapter_text):\n",
    "    return text_before(chapter_text, '.')\n",
    "chapter_number(tale_chapters.column('Chapter text').item(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q1_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rolling Dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Simulate a random roll of a 6-sided fair die. Assume that all sides are equally likely to be obtained from a roll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "die = make_array(1, 2, 3, 4, 5, 6)\n",
    "one_random_roll = np.random.choice(die)\n",
    "one_random_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q2_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Define a function `mean_of_n_rolls` that takes in an integer `n` and returns the mean value of `n` random rolls of a fair die."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_of_n_rolls(n):\n",
    "    return sum(np.random.choice(die, n))/n\n",
    "\n",
    "mean_of_n_rolls(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q2_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Simulate 10 random rolls of a fair die 10,000 times. Record the mean of each set of 10 rolls in an array called `ten_rolls_means`.\n",
    "\n",
    "**Hint:** You may want to use a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.3, 3.9, 3.8, ..., 3.4, 3.2, 2.9])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_rolls_means = make_array()\n",
    "for i in np.arange(10000):\n",
    "    ten_rolls_means = np.append(ten_rolls_means, mean_of_n_rolls(10))\n",
    "\n",
    "ten_rolls_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q2_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once you're finished, select \"Save and Checkpoint\" in the File menu and then execute the `submit` cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to [okpy.org](https://okpy.org/) and flag the correct version. To do so, go to the website, click on this assignment, and find the version you would like to have graded. There should be an option to flag that submission for grading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all tests...\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Question 2_1 > Suite 1 > Case 1\n",
      "\n",
      ">>> 1 <= one_random_roll <= 6\n",
      "NameError: name 'one_random_roll' is not defined\n",
      "\n",
      "# Error: expected\n",
      "#     True\n",
      "# but got\n",
      "#     Traceback (most recent call last):\n",
      "#       ...\n",
      "#     NameError: name 'one_random_roll' is not defined\n",
      "\n",
      "Run only this test case with \"python3 ok -q q2_1 --suite 1 --case 1\"\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 0\n",
      "    Failed: 1\n",
      "[k..........] 0.0% passed\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Question 2_2 > Suite 1 > Case 1\n",
      "\n",
      ">>> mean_of_n_rolls(10000) != mean_of_n_rolls(10000)\n",
      "NameError: name 'mean_of_n_rolls' is not defined\n",
      "\n",
      "# Error: expected\n",
      "#     True\n",
      "# but got\n",
      "#     Traceback (most recent call last):\n",
      "#       ...\n",
      "#     NameError: name 'mean_of_n_rolls' is not defined\n",
      "\n",
      "Run only this test case with \"python3 ok -q q2_2 --suite 1 --case 1\"\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 0\n",
      "    Failed: 1\n",
      "[k..........] 0.0% passed\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Question 2_3 > Suite 1 > Case 1\n",
      "\n",
      ">>> len(ten_rolls_means) == 10000\n",
      "NameError: name 'ten_rolls_means' is not defined\n",
      "\n",
      "# Error: expected\n",
      "#     True\n",
      "# but got\n",
      "#     Traceback (most recent call last):\n",
      "#       ...\n",
      "#     NameError: name 'ten_rolls_means' is not defined\n",
      "\n",
      "Run only this test case with \"python3 ok -q q2_3 --suite 1 --case 1\"\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 0\n",
      "    Failed: 1\n",
      "[k..........] 0.0% passed\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n",
      "Finished running all tests.\n"
     ]
    }
   ],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q') and len(q) <= 10]\n",
    "print(\"Finished running all tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
